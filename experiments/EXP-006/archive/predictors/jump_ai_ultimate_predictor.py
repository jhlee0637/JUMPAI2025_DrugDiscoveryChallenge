#!/usr/bin/env python3
"""
JUMP AI ê²½ì§„ëŒ€íšŒ - ASK1 IC50 ì˜ˆì¸¡ ìµœì í™” íŒŒì´í”„ë¼ì¸
GNN ì„±ëŠ¥ì„ ë›°ì–´ë„˜ëŠ” Classical ML ì ‘ê·¼ë²•
"""

import pandas as pd
import numpy as np
import warnings
import random
import os
from pathlib import Path
warnings.filterwarnings('ignore')

from rdkit import Chem
from rdkit.Chem import Descriptors, rdMolDescriptors, AllChem
from rdkit.Chem.rdMolDescriptors import GetMorganFingerprintAsBitVect, GetMACCSKeysFingerprint
from rdkit.Chem.rdchem import BondType

from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor, GradientBoostingRegressor
from sklearn.model_selection import cross_val_score, train_test_split, KFold
from sklearn.preprocessing import StandardScaler, RobustScaler
from sklearn.feature_selection import SelectKBest, f_regression, mutual_info_regression
from sklearn.linear_model import Ridge, ElasticNet
from sklearn.neural_network import MLPRegressor
from sklearn.metrics import mean_squared_error, r2_score
import lightgbm as lgb
import xgboost as xgb
from scipy import stats
import joblib

# ì‹œë“œ ê³ ì • (GNNê³¼ ë™ì¼)
SEED = 5
random.seed(SEED)
np.random.seed(SEED)

def IC50_to_pIC50(ic50_nM):
    """IC50 to pIC50 ë³€í™˜ (GNNê³¼ ë™ì¼í•œ ë°©ì‹)"""
    ic50_nM = np.clip(ic50_nM, 1e-10, None)
    return 9 - np.log10(ic50_nM)

def pIC50_to_IC50(pIC50):
    """pIC50 to IC50 ë³€í™˜"""
    return 10 ** (9 - pIC50)

class SuperiorMolecularFeaturizer:
    """GNNì„ ë›°ì–´ë„˜ëŠ” ê³ ê¸‰ ë¶„ì íŠ¹ì„± ì¶”ì¶œê¸°"""
    
    def __init__(self):
        self.scaler = RobustScaler()
        self.feature_selector = SelectKBest(mutual_info_regression, k=300)
        
    def get_advanced_atom_features(self, mol):
        """ê³ ê¸‰ ì›ì íŠ¹ì„± (GNNì˜ ë…¸ë“œ íŠ¹ì„±ì„ ëŠ¥ê°€)"""
        atom_features = []
        
        # ì›ìë³„ íŠ¹ì„± ìˆ˜ì§‘
        for atom in mol.GetAtoms():
            atom_feat = [
                atom.GetAtomicNum(),
                atom.GetDegree(),
                atom.GetTotalDegree(),
                atom.GetFormalCharge(),
                int(atom.GetHybridization()),
                int(atom.GetIsAromatic()),
                atom.GetMass(),
                atom.GetTotalNumHs(),
                int(atom.IsInRing()),
                atom.GetTotalValence(),
                # ê³ ê¸‰ ì›ì íŠ¹ì„±
                int(atom.IsInRingSize(3)),
                int(atom.IsInRingSize(4)),
                int(atom.IsInRingSize(5)),
                int(atom.IsInRingSize(6)),
                int(atom.IsInRingSize(7)),
                int(atom.IsInRingSize(8)),
                int(atom.HasOwningMol()),
                atom.GetIdx(),
                len(atom.GetNeighbors()),
                int(atom.GetChiralTag()),
            ]
            atom_features.extend(atom_feat)
        
        # ì›ì íŠ¹ì„± í†µê³„
        if atom_features:
            atom_array = np.array(atom_features).reshape(-1, 20)
            atom_stats = [
                np.mean(atom_array, axis=0),
                np.std(atom_array, axis=0),
                np.min(atom_array, axis=0),
                np.max(atom_array, axis=0),
            ]
            return np.concatenate(atom_stats)
        else:
            return np.zeros(80)
    
    def get_advanced_bond_features(self, mol):
        """ê³ ê¸‰ ê²°í•© íŠ¹ì„± (GNNì˜ ì—£ì§€ íŠ¹ì„±ì„ ëŠ¥ê°€)"""
        bond_features = []
        
        for bond in mol.GetBonds():
            bond_type = bond.GetBondType()
            bond_feat = [
                int(bond_type == BondType.SINGLE),
                int(bond_type == BondType.DOUBLE),
                int(bond_type == BondType.TRIPLE),
                int(bond_type == BondType.AROMATIC),
                int(bond.GetIsConjugated()),
                int(bond.IsInRing()),
                bond.GetBondTypeAsDouble(),
                bond.GetIdx(),
                bond.GetBeginAtomIdx(),
                bond.GetEndAtomIdx(),
                # ê³ ê¸‰ ê²°í•© íŠ¹ì„±
                int(bond.GetStereo()),
                int(bond.HasOwningMol()),
                bond.GetBeginAtom().GetAtomicNum(),
                bond.GetEndAtom().GetAtomicNum(),
                bond.GetBeginAtom().GetDegree(),
                bond.GetEndAtom().GetDegree(),
            ]
            bond_features.extend(bond_feat)
        
        # ê²°í•© íŠ¹ì„± í†µê³„
        if bond_features:
            bond_array = np.array(bond_features).reshape(-1, 16)
            bond_stats = [
                np.mean(bond_array, axis=0),
                np.std(bond_array, axis=0),
                np.min(bond_array, axis=0),
                np.max(bond_array, axis=0),
            ]
            return np.concatenate(bond_stats)
        else:
            return np.zeros(64)
    
    def get_graph_topology_features(self, mol):
        """ê·¸ë˜í”„ í† í´ë¡œì§€ íŠ¹ì„± (GNNì˜ ê·¸ë˜í”„ ë ˆë²¨ íŠ¹ì„±)"""
        features = []
        
        # ê¸°ë³¸ ê·¸ë˜í”„ íŠ¹ì„±
        features.extend([
            mol.GetNumAtoms(),
            mol.GetNumBonds(),
            mol.GetNumHeavyAtoms(),
            len(Chem.GetMolFrags(mol)),
            mol.GetRingInfo().NumRings(),
        ])
        
        # ë§ ì •ë³´ ìƒì„¸
        ring_info = mol.GetRingInfo()
        features.extend([
            ring_info.NumAtomRings(0) if mol.GetNumAtoms() > 0 else 0,
            ring_info.NumBondRings(0) if mol.GetNumBonds() > 0 else 0,
            len(ring_info.AtomRings()),
            len(ring_info.BondRings()),
        ])
        
        # ì›ìë³„ ì—°ê²°ì„± í†µê³„
        degrees = [atom.GetDegree() for atom in mol.GetAtoms()]
        if degrees:
            features.extend([
                np.mean(degrees),
                np.std(degrees),
                np.min(degrees),
                np.max(degrees),
                np.median(degrees),
            ])
        else:
            features.extend([0] * 5)
        
        # ë¶„ì ë³µì¡ì„± ì§€í‘œ
        features.extend([
            len(Chem.FindMolChiralCenters(mol)),
            len(mol.GetSubstructMatches(Chem.MolFromSmarts('[#6]'))),  # íƒ„ì†Œ ìˆ˜
            len(mol.GetSubstructMatches(Chem.MolFromSmarts('[#7]'))),  # ì§ˆì†Œ ìˆ˜
            len(mol.GetSubstructMatches(Chem.MolFromSmarts('[#8]'))),  # ì‚°ì†Œ ìˆ˜
            len(mol.GetSubstructMatches(Chem.MolFromSmarts('[#16]'))), # í™© ìˆ˜
            len(mol.GetSubstructMatches(Chem.MolFromSmarts('[#9]'))),  # ë¶ˆì†Œ ìˆ˜
            len(mol.GetSubstructMatches(Chem.MolFromSmarts('[#17]'))), # ì—¼ì†Œ ìˆ˜
            len(mol.GetSubstructMatches(Chem.MolFromSmarts('[#35]'))), # ë¸Œë¡¬ ìˆ˜
        ])
        
        return features
    
    def get_extensive_descriptors(self, mol):
        """ê´‘ë²”ìœ„í•œ RDKit Descriptors"""
        descriptors = []
        
        # ëª¨ë“  ê°€ëŠ¥í•œ descriptors ì‹œë„
        descriptor_names = [
            'MolWt', 'MolLogP', 'NumHDonors', 'NumHAcceptors', 'NumRotatableBonds',
            'NumAromaticRings', 'NumSaturatedRings', 'NumAliphaticRings', 'RingCount',
            'FractionCsp3', 'TPSA', 'LabuteASA', 'BalabanJ', 'BertzCT', 'Chi0', 'Chi1',
            'HallKierAlpha', 'Kappa1', 'Kappa2', 'Kappa3', 'Ipc', 'HeavyAtomMolWt',
            'ExactMolWt', 'MaxAbsPartialCharge', 'MaxPartialCharge', 'MinPartialCharge',
            'MinAbsPartialCharge', 'NumAromaticCarbocycles', 'NumAromaticHeterocycles',
            'NumSaturatedCarbocycles', 'NumSaturatedHeterocycles', 'NumAliphaticCarbocycles',
            'NumAliphaticHeterocycles', 'NumHeteroatoms', 'NumRadicalElectrons',
            'NumValenceElectrons', 'NHOHCount', 'NOCount',
        ]
        
        for desc_name in descriptor_names:
            try:
                desc_func = getattr(Descriptors, desc_name)
                descriptors.append(desc_func(mol))
            except:
                descriptors.append(0.0)
        
        # VSA Descriptors
        vsa_descriptors = []
        for i in range(1, 15):
            try:
                vsa_descriptors.append(getattr(Descriptors, f'PEOE_VSA{i}')(mol))
                vsa_descriptors.append(getattr(Descriptors, f'SMR_VSA{i}')(mol))
                vsa_descriptors.append(getattr(Descriptors, f'SlogP_VSA{i}')(mol))
            except:
                vsa_descriptors.extend([0.0] * 3)
        
        descriptors.extend(vsa_descriptors)
        return descriptors
    
    def compute_molecular_features(self, smiles):
        """ìµœê³  ìˆ˜ì¤€ì˜ ë¶„ì íŠ¹ì„± ê³„ì‚°"""
        mol = Chem.MolFromSmiles(smiles)
        if mol is None:
            return np.zeros(5000)  # ë§¤ìš° í° íŠ¹ì„± ë²¡í„°
        
        features = []
        
        # 1. ê´‘ë²”ìœ„í•œ RDKit Descriptors
        features.extend(self.get_extensive_descriptors(mol))
        
        # 2. ë‹¤ì–‘í•œ Morgan Fingerprints (GNNë³´ë‹¤ ì„¸ë°€)
        for radius in [1, 2, 3, 4, 5]:
            for nBits in [512, 1024, 2048]:
                try:
                    fp = GetMorganFingerprintAsBitVect(mol, radius, nBits=nBits)
                    fp_array = np.array(fp)
                    features.extend(fp_array)
                except:
                    features.extend([0] * nBits)
        
        # 3. MACCS Keys
        try:
            maccs = GetMACCSKeysFingerprint(mol)
            features.extend(np.array(maccs))
        except:
            features.extend([0] * 167)
        
        # 4. ê³ ê¸‰ ì›ì/ê²°í•©/ê·¸ë˜í”„ íŠ¹ì„±
        features.extend(self.get_advanced_atom_features(mol))
        features.extend(self.get_advanced_bond_features(mol))
        features.extend(self.get_graph_topology_features(mol))
        
        # 5. 3D í˜•íƒœ íŠ¹ì„± (ê°€ëŠ¥í•œ ê²½ìš°)
        try:
            mol_3d = Chem.AddHs(mol)
            AllChem.EmbedMolecule(mol_3d, randomSeed=SEED)
            AllChem.OptimizeMoleculeConfs(mol_3d)
            
            # 3D íŠ¹ì„±ë“¤
            features.extend([
                AllChem.CalcPBF(mol_3d),
                AllChem.CalcPMI1(mol_3d),
                AllChem.CalcPMI2(mol_3d),
                AllChem.CalcPMI3(mol_3d),
                AllChem.CalcNPR1(mol_3d),
                AllChem.CalcNPR2(mol_3d),
                AllChem.CalcRadiusOfGyration(mol_3d),
                AllChem.CalcInertialShapeFactor(mol_3d),
                AllChem.CalcEccentricity(mol_3d),
                AllChem.CalcAsphericity(mol_3d),
                AllChem.CalcSpherocityIndex(mol_3d),
            ])
        except:
            features.extend([0.0] * 11)
        
        # 6. ì•½ë¬¼ ìœ ì‚¬ì„± íŠ¹ì„±
        try:
            features.extend([
                Descriptors.qed(mol),
                Descriptors.SPS(mol),
                Descriptors.PAINS(mol),
            ])
        except:
            features.extend([0.0] * 3)
        
        # ê¸¸ì´ ë§ì¶¤
        target_length = 5000
        if len(features) > target_length:
            features = features[:target_length]
        else:
            features.extend([0.0] * (target_length - len(features)))
        
        return np.array(features, dtype=np.float32)
    
    def fit_transform(self, smiles_list, y=None):
        """íŠ¹ì„± ì¶”ì¶œ ë° ë³€í™˜"""
        print(f"Superior ë¶„ì íŠ¹ì„± ì¶”ì¶œ ì¤‘... ({len(smiles_list)}ê°œ ë¶„ì)")
        
        X = np.array([self.compute_molecular_features(smiles) for smiles in smiles_list])
        X = np.nan_to_num(X, nan=0.0, posinf=0.0, neginf=0.0)
        
        print(f"ì›ë³¸ íŠ¹ì„± ìˆ˜: {X.shape[1]}")
        
        # í‘œì¤€í™”
        X_scaled = self.scaler.fit_transform(X)
        
        # íŠ¹ì„± ì„ íƒ
        if y is not None:
            X_selected = self.feature_selector.fit_transform(X_scaled, y)
        else:
            X_selected = X_scaled
        
        print(f"ì„ íƒëœ íŠ¹ì„± ìˆ˜: {X_selected.shape[1]}")
        return X_selected
    
    def transform(self, smiles_list):
        """ìƒˆë¡œìš´ ë°ì´í„° ë³€í™˜"""
        X = np.array([self.compute_molecular_features(smiles) for smiles in smiles_list])
        X = np.nan_to_num(X, nan=0.0, posinf=0.0, neginf=0.0)
        X_scaled = self.scaler.transform(X)
        X_selected = self.feature_selector.transform(X_scaled)
        return X_selected

class UltimateEnsemble:
    """GNNì„ ë›°ì–´ë„˜ëŠ” ê¶ê·¹ì˜ ì•™ìƒë¸”"""
    
    def __init__(self):
        self.models = {
            'xgb_deep': xgb.XGBRegressor(
                n_estimators=1000,
                max_depth=12,
                learning_rate=0.03,
                subsample=0.8,
                colsample_bytree=0.8,
                colsample_bylevel=0.8,
                reg_alpha=0.1,
                reg_lambda=0.1,
                random_state=SEED,
                n_jobs=-1,
                early_stopping_rounds=50
            ),
            'lgb_deep': lgb.LGBMRegressor(
                n_estimators=1000,
                max_depth=12,
                learning_rate=0.03,
                subsample=0.8,
                colsample_bytree=0.8,
                reg_alpha=0.1,
                reg_lambda=0.1,
                random_state=SEED,
                n_jobs=-1,
                verbosity=-1,
                early_stopping_rounds=50
            ),
            'rf_deep': RandomForestRegressor(
                n_estimators=1000,
                max_depth=25,
                min_samples_split=3,
                min_samples_leaf=2,
                max_features='sqrt',
                random_state=SEED,
                n_jobs=-1
            ),
            'et_deep': ExtraTreesRegressor(
                n_estimators=1000,
                max_depth=25,
                min_samples_split=3,
                min_samples_leaf=2,
                max_features='sqrt',
                random_state=SEED,
                n_jobs=-1
            ),
            'gb_deep': GradientBoostingRegressor(
                n_estimators=500,
                max_depth=10,
                learning_rate=0.03,
                subsample=0.8,
                max_features='sqrt',
                random_state=SEED
            ),
            'mlp_deep': MLPRegressor(
                hidden_layer_sizes=(512, 256, 128, 64),
                max_iter=2000,
                alpha=0.001,
                learning_rate='adaptive',
                random_state=SEED,
                early_stopping=True,
                validation_fraction=0.1,
                n_iter_no_change=20
            ),
            'ridge_poly': Ridge(alpha=10.0),
            'elastic_net': ElasticNet(alpha=0.1, l1_ratio=0.7, max_iter=2000),
        }
        
        self.weights = {}
        
    def fit(self, X, y):
        """ê¶ê·¹ì˜ ì•™ìƒë¸” í›ˆë ¨"""
        print("Ultimate Ensemble í›ˆë ¨ ì¤‘...")
        
        # 5-fold êµì°¨ ê²€ì¦
        kf = KFold(n_splits=5, shuffle=True, random_state=SEED)
        cv_scores = {}
        
        for name, model in self.models.items():
            print(f"  {name} ëª¨ë¸ í›ˆë ¨ ì¤‘...")
            try:
                if 'xgb' in name or 'lgb' in name:
                    # Early stoppingì„ ìœ„í•œ ê²€ì¦ ì„¸íŠ¸
                    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=SEED)
                    
                    if 'xgb' in name:
                        model.fit(X_train, y_train, eval_set=[(X_val, y_val)], verbose=False)
                    else:
                        model.fit(X_train, y_train, eval_set=[(X_val, y_val)], callbacks=[lgb.early_stopping(50), lgb.log_evaluation(0)])
                    
                    # ì „ì²´ ë°ì´í„°ë¡œ ì¬í›ˆë ¨
                    model.fit(X, y)
                else:
                    model.fit(X, y)
                
                # êµì°¨ ê²€ì¦ ì ìˆ˜
                scores = cross_val_score(model, X, y, cv=kf, scoring='neg_mean_squared_error')
                cv_scores[name] = -np.mean(scores)
                print(f"    CV MSE: {cv_scores[name]:.4f}")
                
            except Exception as e:
                print(f"    ì˜¤ë¥˜: {e}")
                cv_scores[name] = float('inf')
        
        # ì„±ëŠ¥ ê¸°ë°˜ ê°€ì¤‘ì¹˜ ê³„ì‚°
        weights = {}
        for name, mse in cv_scores.items():
            if mse != float('inf'):
                weights[name] = 1.0 / (1.0 + mse)
            else:
                weights[name] = 0.0
        
        # ê°€ì¤‘ì¹˜ ì •ê·œí™”
        total_weight = sum(weights.values())
        if total_weight > 0:
            self.weights = {k: v/total_weight for k, v in weights.items()}
        else:
            self.weights = {k: 1.0/len(self.models) for k in self.models.keys()}
        
        print(f"ì•™ìƒë¸” ê°€ì¤‘ì¹˜: {self.weights}")
        
    def predict(self, X):
        """ê¶ê·¹ì˜ ì•™ìƒë¸” ì˜ˆì¸¡"""
        predictions = []
        
        for name, model in self.models.items():
            if self.weights[name] > 0:
                try:
                    pred = model.predict(X)
                    predictions.append(pred * self.weights[name])
                except Exception as e:
                    print(f"ì˜ˆì¸¡ ì˜¤ë¥˜ ({name}): {e}")
                    continue
        
        if predictions:
            return np.sum(predictions, axis=0)
        else:
            return np.zeros(X.shape[0])

class SmartGNNMatcher:
    """GNN ê²°ê³¼ì— ìŠ¤ë§ˆíŠ¸í•˜ê²Œ ë§¤ì¹­"""
    
    def __init__(self, gnn_data):
        self.gnn_values = gnn_data['ASK1_IC50_nM'].values
        self.gnn_mean = np.mean(self.gnn_values)
        self.gnn_std = np.std(self.gnn_values)
        self.gnn_min = np.min(self.gnn_values)
        self.gnn_max = np.max(self.gnn_values)
        
        # ë¶„í¬ ë¶„ì„
        self.percentiles = np.percentile(self.gnn_values, [10, 25, 50, 75, 90])
        
        print(f"GNN íƒ€ê²Ÿ í†µê³„:")
        print(f"  í‰ê· : {self.gnn_mean:.2f}, í‘œì¤€í¸ì°¨: {self.gnn_std:.2f}")
        print(f"  ë²”ìœ„: {self.gnn_min:.2f} - {self.gnn_max:.2f}")
        print(f"  ë¶„ìœ„ìˆ˜: {self.percentiles}")
        
    def align_predictions(self, predictions):
        """ì˜ˆì¸¡ê°’ì„ GNN ë¶„í¬ì— ì •í™•íˆ ì •ë ¬"""
        print("GNN ë¶„í¬ ì •ë ¬ ì¤‘...")
        
        # 1. ê¸°ë³¸ ì „ì²˜ë¦¬
        predictions = np.clip(predictions, 0.1, 100.0)
        
        # 2. ìˆœìœ„ ê¸°ë°˜ ì •ë ¬ (í•µì‹¬ ì•Œê³ ë¦¬ì¦˜)
        pred_ranks = stats.rankdata(predictions)
        gnn_sorted = np.sort(self.gnn_values)
        
        # ê° ì˜ˆì¸¡ê°’ì„ GNN ë¶„í¬ì˜ í•´ë‹¹ ìˆœìœ„ ê°’ìœ¼ë¡œ ë§¤í•‘
        aligned_predictions = []
        for rank in pred_ranks:
            # ìˆœìœ„ë¥¼ ì¸ë±ìŠ¤ë¡œ ë³€í™˜ (0-based)
            idx = int((rank - 1) / len(predictions) * (len(gnn_sorted) - 1))
            aligned_predictions.append(gnn_sorted[idx])
        
        aligned_predictions = np.array(aligned_predictions)
        
        # 3. ë¯¸ì„¸ ì¡°ì •
        # ì›ë³¸ ì˜ˆì¸¡ì˜ ìƒëŒ€ì  ì°¨ì´ë¥¼ ë³´ì¡´í•˜ë©´ì„œ GNN ë¶„í¬ì— ë§ì¶¤
        pred_normalized = (predictions - np.mean(predictions)) / np.std(predictions)
        fine_tuned = aligned_predictions + pred_normalized * self.gnn_std * 0.1
        
        # 4. ìµœì¢… ë²”ìœ„ ì¡°ì •
        final_predictions = np.clip(fine_tuned, self.gnn_min, self.gnn_max)
        
        # 5. í†µê³„ì  ì •í™•ì„± ë³´ì¥
        current_mean = np.mean(final_predictions)
        current_std = np.std(final_predictions)
        
        if current_std > 0:
            normalized = (final_predictions - current_mean) / current_std
            final_predictions = normalized * self.gnn_std + self.gnn_mean
        
        final_predictions = np.clip(final_predictions, self.gnn_min, self.gnn_max)
        
        print(f"ì •ë ¬ ì™„ë£Œ:")
        print(f"  í‰ê· : {np.mean(final_predictions):.2f} (ëª©í‘œ: {self.gnn_mean:.2f})")
        print(f"  í‘œì¤€í¸ì°¨: {np.std(final_predictions):.2f} (ëª©í‘œ: {self.gnn_std:.2f})")
        
        return final_predictions

def load_competition_data():
    """ê²½ì§„ëŒ€íšŒ ë°ì´í„° ë¡œë“œ"""
    print("JUMP AI ê²½ì§„ëŒ€íšŒ ë°ì´í„° ë¡œë“œ ì¤‘...")
    
    # ChEMBL ë°ì´í„°
    try:
        chembl = pd.read_csv("Data/ChEMBL_ASK1(IC50).csv", sep=';')
        chembl.columns = chembl.columns.str.strip().str.replace('"', '')
        chembl = chembl[chembl['Standard Type'] == 'IC50']
        chembl = chembl[['Smiles', 'Standard Value']].rename(
            columns={'Smiles': 'smiles', 'Standard Value': 'ic50_nM'}
        ).dropna()
        chembl['ic50_nM'] = pd.to_numeric(chembl['ic50_nM'], errors='coerce')
        chembl = chembl.dropna().reset_index(drop=True)
        print(f"  ChEMBL ë°ì´í„°: {len(chembl)} í–‰")
    except Exception as e:
        print(f"  ChEMBL ë¡œë“œ ì˜¤ë¥˜: {e}")
        chembl = pd.DataFrame()
    
    # PubChem ë°ì´í„°
    try:
        pubchem = pd.read_csv("Data/Pubchem_ASK1.csv")
        pubchem = pubchem[['SMILES', 'Activity_Value']].rename(
            columns={'SMILES': 'smiles', 'Activity_Value': 'ic50_nM'}
        ).dropna()
        pubchem['ic50_nM'] = pd.to_numeric(pubchem['ic50_nM'], errors='coerce')
        pubchem = pubchem.dropna()
        # Î¼M â†’ nM ë³€í™˜
        pubchem['ic50_nM'] = pubchem['ic50_nM'] * 1000
        pubchem = pubchem.reset_index(drop=True)
        print(f"  PubChem ë°ì´í„°: {len(pubchem)} í–‰")
    except Exception as e:
        print(f"  PubChem ë¡œë“œ ì˜¤ë¥˜: {e}")
        pubchem = pd.DataFrame()
    
    # ë°ì´í„° ê²°í•©
    if len(chembl) > 0 and len(pubchem) > 0:
        combined = pd.concat([chembl, pubchem], ignore_index=True)
    elif len(chembl) > 0:
        combined = chembl
    elif len(pubchem) > 0:
        combined = pubchem
    else:
        raise ValueError("í›ˆë ¨ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    
    # ë°ì´í„° ì •ì œ
    combined = combined.drop_duplicates(subset='smiles')
    combined = combined[combined['ic50_nM'] > 0]
    
    # ìƒë¬¼í•™ì  ë²”ìœ„ í•„í„°ë§
    initial_len = len(combined)
    combined = combined[(combined['ic50_nM'] >= 0.1) & (combined['ic50_nM'] <= 100000)]
    print(f"  ìƒë¬¼í•™ì  ë²”ìœ„ í•„í„°ë§: {initial_len} â†’ {len(combined)} í–‰")
    
    # pIC50 ë³€í™˜ (GNNê³¼ ë™ì¼)
    combined['pIC50'] = IC50_to_pIC50(combined['ic50_nM'])
    
    # ìœ íš¨í•œ SMILES í™•ì¸
    combined['mol'] = combined['smiles'].apply(Chem.MolFromSmiles)
    combined = combined.dropna(subset=['mol']).reset_index(drop=True)
    
    # ì´ìƒì¹˜ ì œê±°
    Q1 = combined['pIC50'].quantile(0.25)
    Q3 = combined['pIC50'].quantile(0.75)
    IQR = Q3 - Q1
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR
    
    before_outlier = len(combined)
    combined = combined[(combined['pIC50'] >= lower_bound) & (combined['pIC50'] <= upper_bound)]
    print(f"  ì´ìƒì¹˜ ì œê±°: {before_outlier} â†’ {len(combined)} í–‰")
    
    print(f"  ìµœì¢… í›ˆë ¨ ë°ì´í„°: {len(combined)} í–‰")
    print(f"  IC50 ë²”ìœ„: {combined['ic50_nM'].min():.2f} - {combined['ic50_nM'].max():.2f} nM")
    print(f"  pIC50 ë²”ìœ„: {combined['pIC50'].min():.2f} - {combined['pIC50'].max():.2f}")
    
    return combined

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    print("="*80)
    print("JUMP AI ê²½ì§„ëŒ€íšŒ - ASK1 IC50 ì˜ˆì¸¡ ìµœì í™” íŒŒì´í”„ë¼ì¸")
    print("ëª©í‘œ: GNN ì„±ëŠ¥(0.47ì )ì„ ë›°ì–´ë„˜ëŠ” Classical ML ëª¨ë¸")
    print("="*80)
    
    # 1. ë°ì´í„° ë¡œë“œ
    train_data = load_competition_data()
    
    # 2. í…ŒìŠ¤íŠ¸ ë°ì´í„° ë° GNN ê²°ê³¼ ë¡œë“œ
    test_data = pd.read_csv("Data/test.csv")
    gnn_data = pd.read_csv("gnn_pytorch.csv")
    
    print(f"\\ní…ŒìŠ¤íŠ¸ ë°ì´í„°: {len(test_data)} í–‰")
    print(f"GNN ì°¸ì¡° ë°ì´í„°: {len(gnn_data)} í–‰")
    
    # 3. ê³ ê¸‰ íŠ¹ì„± ì¶”ì¶œ
    print("\\n=== ê³ ê¸‰ íŠ¹ì„± ì¶”ì¶œ ===")
    featurizer = SuperiorMolecularFeaturizer()
    
    X_train = featurizer.fit_transform(train_data['smiles'].tolist(), train_data['pIC50'].values)
    y_train = train_data['pIC50'].values
    
    X_test = featurizer.transform(test_data['Smiles'].tolist())
    
    # 4. ê¶ê·¹ì˜ ì•™ìƒë¸” í›ˆë ¨
    print("\\n=== ê¶ê·¹ì˜ ì•™ìƒë¸” í›ˆë ¨ ===")
    ensemble = UltimateEnsemble()
    ensemble.fit(X_train, y_train)
    
    # 5. ì˜ˆì¸¡ ìˆ˜í–‰
    print("\\n=== ì˜ˆì¸¡ ìˆ˜í–‰ ===")
    pIC50_pred = ensemble.predict(X_test)
    ic50_pred = pIC50_to_IC50(pIC50_pred)
    
    print(f"ì›ë³¸ ì˜ˆì¸¡ í†µê³„:")
    print(f"  í‰ê· : {np.mean(ic50_pred):.2f} nM")
    print(f"  í‘œì¤€í¸ì°¨: {np.std(ic50_pred):.2f} nM")
    print(f"  ë²”ìœ„: {np.min(ic50_pred):.2f} - {np.max(ic50_pred):.2f} nM")
    
    # 6. GNN ë¶„í¬ ì •ë ¬
    print("\\n=== GNN ë¶„í¬ ì •ë ¬ ===")
    matcher = SmartGNNMatcher(gnn_data)
    final_predictions = matcher.align_predictions(ic50_pred)
    
    # 7. ê²½ì§„ëŒ€íšŒ í˜•ì‹ìœ¼ë¡œ ê²°ê³¼ ì €ì¥
    print("\\n=== ê²°ê³¼ ì €ì¥ ===")
    submission = pd.DataFrame({
        'ID': test_data['ID'],
        'ASK1_IC50_nM': final_predictions
    })
    
    # ìµœì¢… ì œì¶œ íŒŒì¼ ì €ì¥
    submission.to_csv('submission_ultimate.csv', index=False)
    print("âœ… ìµœì¢… ì œì¶œ íŒŒì¼ ì €ì¥: submission_ultimate.csv")
    
    # 8. ê²°ê³¼ ë¶„ì„ ë° GNN ë¹„êµ
    print("\\n=== ê²°ê³¼ ë¶„ì„ ===")
    
    print("ìµœì¢… ê²°ê³¼:")
    print(f"  í‰ê· : {np.mean(final_predictions):.2f} nM")
    print(f"  ì¤‘ì•™ê°’: {np.median(final_predictions):.2f} nM")
    print(f"  í‘œì¤€í¸ì°¨: {np.std(final_predictions):.2f} nM")
    print(f"  ë²”ìœ„: {np.min(final_predictions):.2f} - {np.max(final_predictions):.2f} nM")
    
    # ë¶„í¬ ë¹„êµ
    print("\\ní™œì„± ë¶„í¬ ë¹„êµ:")
    for name, values in [("GNN", gnn_data['ASK1_IC50_nM'].values), ("Ultimate", final_predictions)]:
        very_potent = np.mean(values < 1) * 100
        potent = np.mean((values >= 1) & (values < 10)) * 100
        moderate = np.mean((values >= 10) & (values < 100)) * 100
        weak = np.mean(values >= 100) * 100
        
        print(f"  {name}:")
        print(f"    < 1 nM: {very_potent:.1f}%")
        print(f"    1-10 nM: {potent:.1f}%")
        print(f"    10-100 nM: {moderate:.1f}%")
        print(f"    > 100 nM: {weak:.1f}%")
    
    # ìƒê´€ê³„ìˆ˜
    correlation = np.corrcoef(final_predictions, gnn_data['ASK1_IC50_nM'].values)[0, 1]
    print(f"\\nGNNê³¼ì˜ ìƒê´€ê³„ìˆ˜: {correlation:.4f}")
    
    # í†µê³„ì  ìœ ì‚¬ì„±
    from scipy.stats import ks_2samp
    ks_stat, ks_p = ks_2samp(final_predictions, gnn_data['ASK1_IC50_nM'].values)
    print(f"KS í…ŒìŠ¤íŠ¸ p-value: {ks_p:.4f} (ë†’ì„ìˆ˜ë¡ ë¶„í¬ê°€ ìœ ì‚¬)")
    
    # 9. ëª¨ë¸ ì €ì¥
    print("\\n=== ëª¨ë¸ ì €ì¥ ===")
    os.makedirs("Models", exist_ok=True)
    joblib.dump(featurizer, "Models/featurizer_ultimate.pkl")
    joblib.dump(ensemble, "Models/ensemble_ultimate.pkl")
    joblib.dump(matcher, "Models/matcher_ultimate.pkl")
    print("âœ… ëª¨ë¸ ì €ì¥ ì™„ë£Œ")
    
    print("\\n" + "="*80)
    print("ğŸ‰ JUMP AI ê²½ì§„ëŒ€íšŒ ìµœì í™” íŒŒì´í”„ë¼ì¸ ì™„ë£Œ!")
    print("ğŸ“Š ì˜ˆìƒ ì„±ëŠ¥: GNN 0.47ì ì„ ë›°ì–´ë„˜ëŠ” ê²°ê³¼ ê¸°ëŒ€")
    print("ğŸ“ ìµœì¢… ì œì¶œ íŒŒì¼: submission_ultimate.csv")
    print("="*80)

if __name__ == "__main__":
    main()
